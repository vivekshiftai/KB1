# ğŸ–¼ï¸ Image Flow Through the System

## Complete Image Journey from PDF to Query Response

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PDF UPLOAD                               â”‚
â”‚  User uploads PDF with images                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MINERU PROCESSING                            â”‚
â”‚                                                                 â”‚
â”‚ 1. MinerU extracts PDF content                                 â”‚
â”‚ 2. Converts to Markdown with image references                  â”‚
â”‚ 3. Saves images as separate files in output directory          â”‚
â”‚ 4. Creates markdown files with ![](image_path) references      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHUNKING PROCESS                             â”‚
â”‚                                                                 â”‚
â”‚ MarkdownChunker.process_directory()                            â”‚
â”‚                                                                 â”‚
â”‚ For each markdown file:                                        â”‚
â”‚ 1. Parse markdown content                                       â”‚
â”‚ 2. Extract image references: ![](path/to/image.jpg)           â”‚
â”‚ 3. For each image found:                                       â”‚
â”‚    a. Check if should embed (always True)                      â”‚
â”‚    b. Load image file from disk                                â”‚
â”‚    c. Compress if needed (OpenCV)                              â”‚
â”‚    d. Convert to base64                                        â”‚
â”‚    e. Create ImageData object                                  â”‚
â”‚                                                                 â”‚
â”‚ ImageData {                                                     â”‚
â”‚   filename: "image.jpg",                                       â”‚
â”‚   data: "base64_encoded_data...",                              â”‚
â”‚   mime_type: "image/jpeg",                                     â”‚
â”‚   size: 12345                                                  â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHUNK CREATION                               â”‚
â”‚                                                                 â”‚
â”‚ ChunkData {                                                     â”‚
â”‚   heading: "Safety Requirements",                              â”‚
â”‚   text: "Markdown content with text...",                       â”‚
â”‚   image_paths: ["path/to/image.jpg"],                          â”‚
â”‚   embedded_images: [ImageData objects],                        â”‚
â”‚   tables: ["<table>...</table>"]                               â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR DATABASE STORAGE                      â”‚
â”‚                                                                 â”‚
â”‚ VectorDatabase.store_chunks()                                  â”‚
â”‚                                                                 â”‚
â”‚ For each chunk:                                                â”‚
â”‚ 1. Create embedding from text content                          â”‚
â”‚ 2. Store in ChromaDB with metadata:                            â”‚
â”‚                                                                 â”‚
â”‚ ChromaDB Document {                                             â”‚
â”‚   id: "chunk-0",                                               â”‚
â”‚   document: "chunk text content",                              â”‚
â”‚   embedding: [0.1, 0.2, 0.3, ...],                            â”‚
â”‚   metadata: {                                                  â”‚
â”‚     "heading": "Safety Requirements",                          â”‚
â”‚     "image_paths": '["path/to/image.jpg"]',                    â”‚
â”‚     "embedded_images": '[{"filename": "image.jpg",             â”‚
â”‚                          "data": "base64_data...",             â”‚
â”‚                          "mime_type": "image/jpeg",            â”‚
â”‚                          "size": 12345}]',                     â”‚
â”‚     "tables": '["<table>...</table>"]'                         â”‚
â”‚   }                                                             â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUERY PROCESSING                             â”‚
â”‚                                                                 â”‚
â”‚ LangGraphQueryProcessor.process_query()                        â”‚
â”‚                                                                 â”‚
â”‚ 1. Retrieve chunks from vector database                        â”‚
â”‚ 2. Chunks come with embedded_images already loaded             â”‚
â”‚ 3. LLM processes chunks (ignores images)                       â”‚
â”‚ 4. Response validation and retry logic                         â”‚
â”‚ 5. Collect images from used chunks                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE COLLECTION                             â”‚
â”‚                                                                 â”‚
â”‚ _collect_media_from_chunks()                                   â”‚
â”‚                                                                 â”‚
â”‚ 1. Find chunks used by LLM response                            â”‚
â”‚ 2. Extract embedded_images from those chunks                   â”‚
â”‚ 3. Deduplicate by filename                                     â”‚
â”‚ 4. Return ImageData objects ready for response                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINAL RESPONSE                               â”‚
â”‚                                                                 â”‚
â”‚ QueryResponse {                                                 â”‚
â”‚   success: true,                                               â”‚
â”‚   message: "Query processed successfully",                     â”‚
â”‚   response: "LLM generated response...",                       â”‚
â”‚   chunks_used: ["Safety Requirements"],                        â”‚
â”‚   images: [ImageData objects with base64 data],                â”‚
â”‚   tables: ["<table>...</table>"],                              â”‚
â”‚   processing_time: "2.34s"                                     â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Key Points About Image Flow

### **1. Image Embedding During Chunking**
- Images are **converted to base64** during the chunking process
- **Compression** is applied if images are too large
- Images are **stored directly in chunk metadata**

### **2. No External Image Queries**
- Images travel with chunks through the entire pipeline
- **No separate database queries** needed for images
- Images are **immediately available** when chunks are retrieved

### **3. Image Processing Steps**
```
PDF Image â†’ MinerU Extraction â†’ File System â†’ Chunking â†’ Base64 â†’ Vector DB â†’ Query Response
```

### **4. Image Data Structure**
```python
ImageData {
    filename: "safety_diagram.jpg",
    data: "iVBORw0KGgoAAAANSUhEUgAA...",  # Base64 encoded
    mime_type: "image/jpeg",
    size: 12345
}
```

### **5. Storage in Vector Database**
```python
# Stored in ChromaDB metadata
metadata = {
    "heading": "Safety Requirements",
    "embedded_images": '[{"filename": "image.jpg", "data": "base64...", "mime_type": "image/jpeg", "size": 12345}]'
}
```

## ğŸš€ Benefits of This Approach

1. **Fast Access**: Images are immediately available with chunks
2. **No Extra Queries**: No need to fetch images separately
3. **Consistent Context**: Images stay with their relevant text
4. **Efficient Storage**: Base64 encoding with compression
5. **Reliable**: No dependency on external file systems during queries

## ğŸ“Š Image Flow Summary

- **Upload**: PDF with images
- **Extract**: MinerU saves images as files + markdown references
- **Chunk**: Convert images to base64 and embed in chunks
- **Store**: Save chunks with embedded images in vector database
- **Query**: Retrieve chunks with images already included
- **Response**: Return images directly from chunk data

The images flow seamlessly through the entire pipeline, always staying with their relevant text content! ğŸ¯
